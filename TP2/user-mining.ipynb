{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "\n",
    "# !!!! borrar, va en otro notebook\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Setting random seed.\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = pd.read_csv('./data/events_up_to_01062018.csv', low_memory=False)\n",
    "df_sessions = pd.read_csv('./data/sessions.csv', low_memory=False)\n",
    "df_brands = pd.read_csv('data/brands.csv')\n",
    "df_os = pd.read_csv('data/os.csv')\n",
    "df_browsers = pd.read_csv('data/browsers.csv')\n",
    "df_y = pd.read_csv('data/labels_training_set.csv')\n",
    "df_y = df_y.groupby('person').sum()\n",
    "\n",
    "\n",
    "df = df_events.merge(df_sessions, how='left', left_index=True, right_index=True)\n",
    "df = df.merge(df_browsers, how='left', on='browser_version')\n",
    "df = df.merge(df_os, how='left', on='operating_system_version')\n",
    "df = df.merge(df_brands, how='left', on='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los atributos con pocos valores posibles se pasan a variables categoricas para ahorrar memoria\n",
    "df['event'] = df['event'].astype('category')\n",
    "df['condition'] = df['condition'].astype('category')\n",
    "df['storage'] = df['storage'].astype('category')\n",
    "df['search_engine'] = df['search_engine'].astype('category')\n",
    "df['channel'] = df['channel'].astype('category')\n",
    "df['device_type'] = df['device_type'].astype('category')\n",
    "\n",
    "df['brand'] = df['brand'].astype('category')\n",
    "df['operating_system'] = df['operating_system'].astype('category')\n",
    "df['browser'] = df['browser'].astype('category')\n",
    "\n",
    "# El tiempo es mejor manejarlo como tal\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month_number'] = df['timestamp'].dt.month\n",
    "df['month_name'] = df['month_number'].apply(lambda x: calendar.month_abbr[x])\n",
    "df['week_day'] = df['timestamp'].dt.weekday\n",
    "df['week_number'] = df['timestamp'].dt.week\n",
    "df['week_day_name'] = df['timestamp'].dt.weekday_name\n",
    "df['day_date'] = df['timestamp'].dt.to_period('D')\n",
    "df['day_dom'] = df['timestamp'].dt.day\n",
    "df['day_doy'] = df['timestamp'].dt.dayofyear\n",
    "df['hour_count'] = df['timestamp'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_conversion'] = df['event'] == 'conversion'\n",
    "df['is_checkout'] = df['event'] == 'checkout'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total checkouts and conversions\n",
    "udf_tmp1 = df.groupby('person').agg({'is_conversion':'sum', 'is_checkout':'sum'})\n",
    "udf_tmp1.columns = ['total_conversions', 'total_checkouts']\n",
    "udf_tmp1['total_conversions'] = udf_tmp1['total_conversions'].astype('int')\n",
    "udf_tmp1['total_checkouts'] = udf_tmp1['total_checkouts'].astype('int')\n",
    "\n",
    "udf_tmp1['has_conversion'] = udf_tmp1['total_conversions'] > 0\n",
    "udf_tmp1['has_checkout'] = udf_tmp1['total_checkouts'] > 0\n",
    "\n",
    "udf_tmp1 = udf_tmp1.astype('int') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(udf_tmp1))\n",
    "udf_tmp1[udf_tmp1['total_conversions'] > 10].sort_values('total_conversions', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_tmp2 = df['person'].drop_duplicates().to_frame().set_index('person')\n",
    "display(udf_tmp2.head())\n",
    "\n",
    "for i in range(1,6):\n",
    "    gb = df[df['month_number'] == i].groupby('person')\n",
    "    udf_tmp2i = gb.agg({'is_conversion':'sum', 'is_checkout':'sum'})\n",
    "    udf_tmp2i.columns = ['total_conversions_month_{}'.format(i), 'total_checkouts_month_{}'.format(i)]\n",
    "\n",
    "    udf_tmp2i['total_conversions_month_{}'.format(i)] = udf_tmp2i['total_conversions_month_{}'.format(i)].astype('int')\n",
    "    udf_tmp2i['total_checkouts_month_{}'.format(i)] = udf_tmp2i['total_checkouts_month_{}'.format(i)].astype('int')\n",
    "\n",
    "    udf_tmp2i['has_conversion_month_{}'.format(i)] = udf_tmp2i['total_conversions_month_{}'.format(i)] > 0\n",
    "    udf_tmp2i['has_checkout_month_{}'.format(i)] = udf_tmp2i['total_checkouts_month_{}'.format(i)] > 0\n",
    "\n",
    "    display(udf_tmp2i.head(2))\n",
    "    udf_tmp2 = udf_tmp2.merge(udf_tmp2i, how='outer', left_index=True, right_index=True)\n",
    "    display(udf_tmp2.head(2))\n",
    "\n",
    "udf_tmp2 = udf_tmp2.fillna(0)\n",
    "udf_tmp2 = udf_tmp2.astype('int')\n",
    "udf_tmp2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has conversions or checkouts in may\n",
    "gb = df[df['month_number'] != 5].groupby('person')\n",
    "udf_tmp3 = gb.agg({'is_conversion':'sum', 'is_checkout':'sum'})\n",
    "udf_tmp3.columns = ['total_conversions_month_1_4', 'total_checkouts_month_1_4']\n",
    "\n",
    "udf_tmp3['total_conversions_month_1_4'] = udf_tmp3['total_conversions_month_1_4'].astype('int')\n",
    "udf_tmp3['total_checkouts_month_1_4'] = udf_tmp3['total_checkouts_month_1_4'].astype('int')\n",
    "\n",
    "udf_tmp3['has_conversion_month_1_4'] = udf_tmp3['total_conversions_month_1_4'] > 0\n",
    "udf_tmp3['has_checkout_month_1_4'] = udf_tmp3['total_checkouts_month_1_4'] > 0\n",
    "\n",
    "udf_tmp3 = udf_tmp3.astype('int')\n",
    "udf_tmp3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has conversions or checkouts in may\n",
    "gb = df[df['timestamp'] > pd.to_datetime('2018-05-23')].groupby('person')\n",
    "udf_tmp4 = gb.agg({'is_conversion':'sum', 'is_checkout':'sum'})\n",
    "udf_tmp4.columns = ['total_conversions_last_week', 'total_checkouts_last_week']\n",
    "\n",
    "udf_tmp4['total_conversions_last_week'] = udf_tmp4['total_conversions_last_week'].astype('int')\n",
    "udf_tmp4['total_checkouts_last_week'] = udf_tmp4['total_checkouts_last_week'].astype('int')\n",
    "\n",
    "udf_tmp4['has_conversion_last_week'] = udf_tmp4['total_conversions_last_week'] > 0\n",
    "udf_tmp4['has_checkout_last_week'] = udf_tmp4['total_checkouts_last_week'] > 0\n",
    "\n",
    "udf_tmp4 = udf_tmp4.astype('int')\n",
    "udf_tmp4.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_tmp5 = udf_tmp2['has_conversion_month_1']\n",
    "display(len(udf_tmp2))\n",
    "display(len(udf_tmp5))\n",
    "for i in range(2,6):\n",
    "    udf_tmp5 = udf_tmp5 + udf_tmp2['has_conversion_month_{}'.format(i)]\n",
    "    \n",
    "udf_tmp5 = udf_tmp5.to_frame()\n",
    "udf_tmp5.columns = ['amount_of_months_that_has_bought']\n",
    "\n",
    "for i in range(6):\n",
    "    print('Users that have bought in {} different months: {}'.format(i, len(udf_tmp5[udf_tmp5['amount_of_months_that_has_bought'] >= i])))\n",
    "\n",
    "udf_tmp5.head(5)\n",
    "udf_tmp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf = udf_tmp1\n",
    "udf = udf.merge(udf_tmp2, how='outer', on='person')\n",
    "udf = udf.merge(udf_tmp3, how='outer', on='person')\n",
    "udf = udf.merge(udf_tmp4, how='outer', on='person')\n",
    "udf = udf.merge(udf_tmp5, how='outer', on='person')\n",
    "udf = udf.fillna(0)\n",
    "udf = udf.astype('int')\n",
    "display(len(udf))\n",
    "udf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(udf))\n",
    "display(len(df_events['person'].unique()))\n",
    "display(len(df['person'].unique()))\n",
    "udf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummys de todos 0s y todos 1s\n",
    "gb = df[['person', 'week_number']].groupby('person')\n",
    "dummy = gb.agg('sum')\n",
    "\n",
    "dummy = dummy['week_number'] * 0\n",
    "dummy = dummy.to_frame()\n",
    "print(\"dummy-size: \"+str(len(dummy))+\" | y-size: \"+str(len(df_y)))\n",
    "y_df_tmp = y_df.set_index(y_df['person'])[['label']]\n",
    "\n",
    "dummy_final = dummy.merge(y_df_tmp, how='outer', left_index=True, right_index=True, indicator=True)\n",
    "#display(dummy.head())\n",
    "#display(y_df.head())\n",
    "#display(dummy_final.head())\n",
    "dummy['label'] = dummy['week_number'] * 0\n",
    "dummy = dummy[['label']]\n",
    "dummy = dummy[~dummy.index.isin(y_df.index)]\n",
    "display(len(dummy))\n",
    "dummy\n",
    "display(len(dummy_final.query('_merge != \"both\"')))\n",
    "dummy_final = dummy_final.query('_merge != \"both\"')[['week_number']]\n",
    "dummy_final.columns = ['label']\n",
    "dummy_final['label'] = dummy_final['label'] + 1\n",
    "print(\"checking sum is zero: \")\n",
    "display(dummy_final.sum())\n",
    "dummy_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_final.to_csv('submit-zeros.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Siguiente minado>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def require(x1, x2):\n",
    "    if x1 != x2:\n",
    "        print('ERROR - {} must be equal to {}'.format(str(x1), str(x2)))\n",
    "        raise ValueError('Oh la la.') \n",
    "\n",
    "def df_label_xor(df1, df2):\n",
    "    \n",
    "    merged = df1.merge(df2, how='outer', left_index=True, right_index=True, indicator=True)\n",
    "    merged = merged.query('_merge != \"both\"')\n",
    "    return merged\n",
    "    \n",
    "# Crea la matriz X y el vector y para entrenar\n",
    "def fr1_extract_X_y(df, df_y):\n",
    "    require(len(df), 38829)\n",
    "    require(len(df_y), 19414)\n",
    "    \n",
    "    data = df.merge(df_y, how='inner', left_index= True, right_index=True)\n",
    "    require(len(data), 19414)\n",
    "    \n",
    "    X = data.drop('label', axis=1).values\n",
    "    y = df_y.values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Splitea para generar los set de entrenamiento y de prueba\n",
    "def fr2_train_test_split(X, y, seed):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=0.34,\n",
    "                                                        stratify=y,\n",
    "                                                        random_state=seed)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Customizado, se tiene que hacer uno por algoritmo\n",
    "def fr3_decision_tree(X_train, X_test, y_train, seed):\n",
    "    tree = DecisionTreeClassifier(criterion='gini',\n",
    "                              min_samples_leaf=5,\n",
    "                              min_samples_split=5,\n",
    "                              max_depth=3,\n",
    "                              random_state=seed)\n",
    "\n",
    "    tree.fit(X_train, y_train)\n",
    "    return tree\n",
    "\n",
    "def fr3_random_forest(X_train, X_test, y_train, seed):\n",
    "    rf = RandomForestClassifier(n_estimators=20,\n",
    "                           n_jobs=2,\n",
    "                           min_samples_split=300,\n",
    "                           random_state=seed,\n",
    "                           class_weight='balanced')\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    return rf\n",
    "    \n",
    "def fr3_knn(X_train, X_test, y_train, seed, k):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='uniform', n_jobs=-1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn\n",
    "\n",
    "def fr4_accuracy_score(X_test, y_test, model, model_name):\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('[fr4] {} accuracy score: {}'.format(model_name, accuracy))    \n",
    "    \n",
    "# Crea la matriz X a predecir\n",
    "def fr5_extract_X_to_predict(df, df_y, model):\n",
    "    require(len(df), 38829)\n",
    "    require(len(df_y), 19414)\n",
    "       \n",
    "    data = df_label_xor(df, df_y)\n",
    "    data = data.drop(['label', '_merge'], axis=1)\n",
    "\n",
    "    require(len(data), 19415)\n",
    "    predictions = model.predict_proba(data.values)\n",
    "    \n",
    "    predictions_list = []\n",
    "    for i in predictions:\n",
    "        predictions_list.append(i[1])\n",
    "    predictions_final = np.array(predictions_list)\n",
    "    \n",
    "    print(\"[fr5] predictions: {}\".format(predictions_final))\n",
    "\n",
    "    return data, predictions_final\n",
    "\n",
    "# Devuelve la cantidad de 1s predecidos\n",
    "def fr6_print_information(df, predictions, model, X_to_predict):\n",
    "    print('[fr6] Ammount of 1s: {}'.format(model.predict(X_to_predict).sum()))\n",
    "    \n",
    "    #feature_importances = pd.DataFrame(model.feature_importances_,\n",
    "    #                              index=df.columns,\n",
    "    #                              columns=['importance'])\n",
    "    #feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "\n",
    "    #display(feature_importances)\n",
    "    \n",
    "    \n",
    "def fr7_to_csv(df, predictions, name_csv):\n",
    "    submission = df\n",
    "    submission['label'] = predictions\n",
    "    submission = submission['label']\n",
    "    \n",
    "    require(len(submission), 19415)\n",
    "    \n",
    "    submission.to_csv(name_csv, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Decission Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Framework para entrenar\n",
    "\n",
    "# SÓLO CAMBIAR ESTOS PARÁMETROS\n",
    "fr_df, fr_df_y = udf, df_y\n",
    "\n",
    "# De acá no tienen que tocar nada\n",
    "X, y = fr1_extract_X_y(fr_df, fr_df_y)\n",
    "X_train, X_test, y_train, y_test = fr2_train_test_split(X, y, seed)\n",
    "fr_model = fr3_decision_tree(X_train, X_test, y_train, seed)\n",
    "fr4_accuracy_score(X_test, y_test, fr_model, 'DecissionTreeClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Framework para predecir, luego se submitea el archivo generado\n",
    "\n",
    "# SÓLO CAMBIAR ESTOS PARÁMETROS\n",
    "\n",
    "# De acá no tienen que tocar nada\n",
    "X_to_predict, predictions = fr5_extract_X_to_predict(fr_df, fr_df_y, fr_model)\n",
    "fr6_print_information(fr_df, predictions, fr_model, X_to_predict)\n",
    "fr7_to_csv(X_to_predict, predictions, 'submission-decission-tree-1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Framework para entrenar\n",
    "\n",
    "# SÓLO CAMBIAR ESTOS PARÁMETROS\n",
    "cols1 = ['total_checkouts_month_5', 'total_conversions_month_5', 'total_conversions', 'total_conversions_month_1_4', 'has_conversion_month_1_4']\n",
    "cols2 = ['total_checkouts_last_week', 'total_conversions_month_5', 'total_conversions', 'total_conversions_month_1_4', 'has_conversion_month_1_4']\n",
    "cols3 = ['total_checkouts_last_week', 'total_checkouts', 'total_conversions_month_5', 'amount_of_months_that_has_bought']\n",
    "fr_df, fr_df_y = udf, df_y\n",
    "\n",
    "# De acá no tienen que tocar nada\n",
    "X, y = fr1_extract_X_y(fr_df, fr_df_y)\n",
    "X_train, X_test, y_train, y_test = fr2_train_test_split(X, y, seed)\n",
    "fr_model = fr3_random_forest(X_train, X_test, y_train, seed)\n",
    "fr4_accuracy_score(X_test, y_test, fr_model, 'RandomForestClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Framework para predecir, luego se submitea el archivo generado\n",
    "\n",
    "# SÓLO CAMBIAR ESTOS PARÁMETROS\n",
    "\n",
    "# De acá no tienen que tocar nada\n",
    "X_to_predict, predictions = fr5_extract_X_to_predict(fr_df, fr_df_y, fr_model)\n",
    "fr6_print_information(fr_df, predictions, fr_model, X_to_predict)\n",
    "fr7_to_csv(X_to_predict, predictions, 'submission-decission-tree-1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. KNN Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rango = 5\n",
    "def knn_gridsearch(x_train, y_train, x_test, y_test):\n",
    "    k_max = (0,0)\n",
    "    for k in range(1,100, rango):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights='uniform', n_jobs=-1)\n",
    "        knn.fit(x_train, y_train)\n",
    "        score = knn.score(x_test, y_test)*100\n",
    "        if score > k_max[1]:\n",
    "            k_max = (k,score)\n",
    "        #print(\"K: {}, {}\".format(k, score))\n",
    "    a = k_max[0]\n",
    "    k_max = (0,0)\n",
    "    for k in range(a - rango, a + rango):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights='uniform', n_jobs=-1)\n",
    "        knn.fit(x_train, y_train)\n",
    "        score = knn.score(x_test, y_test)*100\n",
    "        if score > k_max[1]:\n",
    "            k_max = (k,score)\n",
    "        print(\"K: {}, {}\".format(k, score))\n",
    "    return k_max[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_df, fr_df_y = udf, df_y\n",
    "X, y = fr1_extract_X_y(fr_df, fr_df_y)\n",
    "X_train, X_test, y_train, y_test = fr2_train_test_split(X, y, seed)\n",
    "\n",
    "#Hacemos el Grid Search\n",
    "k = knn_gridsearch(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos el modelo\n",
    "fr_model = fr3_knn(X_train, X_test, y_train, seed, k)\n",
    "fr4_accuracy_score(X_test, y_test, fr_model, 'KNNGridsearch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Framework para predecir, luego se submitea el archivo generado\n",
    "\n",
    "# SÓLO CAMBIAR ESTOS PARÁMETROS\n",
    "\n",
    "# De acá no tienen que tocar nada\n",
    "X_to_predict, predictions = fr5_extract_X_to_predict(fr_df, fr_df_y, fr_model)\n",
    "\n",
    "fr6_print_information(fr_df, predictions_final, fr_model, X_to_predict)\n",
    "fr7_to_csv(X_to_predict, predictions_final, 'submission-knn-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
