{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [75.06 / 95.58] Organización de Datos <br> Trabajo Práctico 2: Machine Learning\n",
    "# Parameter Tuning\n",
    "\n",
    "**Grupo 30: Datatouille**\n",
    "\n",
    "**http://fdelmazo.github.io/7506-Datos/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hiper_params():\n",
    "    # Se esconde en un def para poder importarlo\n",
    "\n",
    "    return {\n",
    "        'decision_tree':{'criterion': 'entropy',\n",
    "                                     'max_features': 0.1,\n",
    "                                     'max_depth': 1.0,\n",
    "                                     'min_samples_split': 0.1,\n",
    "                                     'min_samples_leaf': 0.1},\n",
    "\n",
    "        'random_forest': {'n_estimators': 200,\n",
    "                                     'criterion': 'gini',\n",
    "                                     'max_features': 0.3,\n",
    "                                     'max_depth': 1.0,\n",
    "                                     'min_samples_split': 0.1,\n",
    "                                     'min_samples_leaf': 0.1},\n",
    "        \n",
    "        'xgboost': {'learning_rate': 0.1,\n",
    "                     'objective': 'binary:logistic',\n",
    "                     'n_estimators': 200,\n",
    "                     'scale_pos_weight': 2,\n",
    "                     'max_depth': 1,\n",
    "                     'min_child_weight': 1,\n",
    "                     'gamma': 0.0,\n",
    "                     'colsample_bytree': 0.79,\n",
    "                     'subsample': 0.89,\n",
    "                     'reg_alpha': 100},\n",
    "        \n",
    "        'knn': {'n_neighbors':21, 'weights':'uniform', 'n_jobs':-1},\n",
    "        \n",
    "        'naive_bayes' : {'var_smoothing': 1e-09},\n",
    "        \n",
    "        'lightgbm': {'bagging_fraction': 0.8,\n",
    "                     'feature_fraction': 0.1,\n",
    "                     'lambda_l1': 4,\n",
    "                     'lambda_l2': 0,\n",
    "                     'max_depth': 5,\n",
    "                     'min_child_weight': 8,\n",
    "                     'min_split_gain': 0.001,\n",
    "                     'num_leaves': 24},\n",
    "        \n",
    "        'catboost': { 'eval_metric': 'AUC',\n",
    "                     'iterations': 678,\n",
    "                     'random_strength': 42,\n",
    "                     'learning_rate': 0.01,\n",
    "                     'depth': 1,\n",
    "                     'l2_leaf_reg': 2},\n",
    "        \n",
    "        'gradient_boosting': {'max_leaf_nodes': None,\n",
    "                     'min_weight_fraction_leaf': 0,\n",
    "                     'learning_rate': 0.1,\n",
    "                     'max_features': 1,\n",
    "                     'min_samples_split': 1.0,\n",
    "                     'min_samples_leaf': 0.1,\n",
    "                     'max_depth': 1.0,\n",
    "                     'n_estimators': 1,\n",
    "                     'subsample': 0.8,\n",
    "                     'loss': 'deviance',\n",
    "                     'warm_start': False,\n",
    "                     'presort': 'auto'},\n",
    "        \n",
    "        'neuralnetwork': {'activation':'relu', 'alpha':1e-05, 'beta_1':0.9, \n",
    "          'beta_2':0.999, 'early_stopping':False, 'epsilon':1e-08, \n",
    "          'hidden_layer_sizes':(4, 7), 'learning_rate':'constant', \n",
    "          'learning_rate_init':0.001, 'max_iter':200, 'momentum':0.9, \n",
    "          'nesterovs_momentum':True, 'power_t':0.5, 'random_state':42, \n",
    "          'shuffle':True, 'solver':'adam', 'tol':0.0001, 'validation_fraction':0.1, 'verbose':False, \n",
    "          'warm_start':False}\n",
    "        \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter # pip install nbimporter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import submission_framework as SF\n",
    "\n",
    "df_users = pd.read_csv('data/user-features.csv',low_memory=False).set_index('person')\n",
    "df_y = pd.read_csv('data/labels_training_set.csv').groupby('person').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_mano = ['dow_last_conversion', 'has_conversion_last_week', \n",
    "                         'total_conversions_month_4', 'total_session_checkouts', \n",
    "                         'doy_last_conversion', 'timestamp_last_event', \n",
    "                         'dow_last_checkout', 'total_checkouts', \n",
    "                         'has_checkout', 'doy_last_checkout', \n",
    "                         'has_checkout_month_1', 'timestamp_last_checkout', \n",
    "                         'total_sessions', 'woy_last_event', 'has_checkout_month_5', \n",
    "                         'avg_events_per_session']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_params(df_x, df_y, orig_model_with_name, columns, default_params, list_of_progressive_params,seed=42,cv=5):\n",
    "    \n",
    "    orig_model_name, orig_model = orig_model_with_name\n",
    "    orig_model_name+='_GS'\n",
    "    params = {}\n",
    "    params_grid = {}\n",
    "    i=1\n",
    "    \n",
    "    for params_grid in list_of_progressive_params:\n",
    "        print(f\"Best Params So Far: {default_params} {params}\")\n",
    "        if not seed == -1: model_new = GridSearchCV(orig_model(**default_params,**params,random_state=seed),params_grid,cv=cv,verbose=1)\n",
    "        else: model_new = GridSearchCV(orig_model(**default_params,**params),params_grid,cv=cv,verbose=1)\n",
    "        model_with_name = (orig_model_name,model_new)\n",
    "        model, auc = SF.full_framework_wrapper(df_x, df_y, model_with_name,columns=columnas_a_mano)\n",
    "        params.update(model.best_params_)\n",
    "        i+=1\n",
    "\n",
    "    default_params.update(params)\n",
    "    return default_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "> https://medium.com/@mohtedibf/indepth-parameter-tuning-for-decision-tree-6753118a03c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "  \n",
    "list_of_progressive_params = [{'criterion':['gini','entropy']},\n",
    "                              {'max_features': np.arange(0.1,0.4,0.1)},\n",
    "                              {'max_depth': np.linspace(1, 32, 5, endpoint=True)},\n",
    "                              {'min_samples_split': np.linspace(0.1, 1.0, 10, endpoint=True)},\n",
    "                              {'min_samples_leaf': np.linspace(0.1, 0.5, 5, endpoint=True)}\n",
    "]\n",
    "\n",
    "model_with_name = ('decision_tree', DecisionTreeClassifier)\n",
    "\n",
    "best_params_decision_tree = find_best_params(df_users,df_y,model_with_name,columnas_a_mano, {},list_of_progressive_params) \n",
    "best_params_decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "> https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "   \n",
    "list_of_progressive_params = [{'n_estimators':[1, 2, 4, 8, 16, 32, 64, 100, 200]},\n",
    "                              {'criterion':['gini','entropy']},\n",
    "                              {'max_features': np.arange(0.1,0.4,0.1)},\n",
    "                              {'max_depth': np.linspace(1, 32, 3, endpoint=True)},\n",
    "                              {'min_samples_split': np.arange(0.1, 1.0, 0.1)},\n",
    "                              {'min_samples_leaf': np.linspace(0.1, 0.5, 5, endpoint=True)}\n",
    "                   ]  \n",
    "\n",
    "model_with_name = ('random_forest', RandomForestClassifier)\n",
    "\n",
    "best_params_random_forest = find_best_params(df_users,df_y,model_with_name,columnas_a_mano, {},list_of_progressive_params) \n",
    "best_params_random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "> https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb #conda install -c conda-forge xgboost \n",
    "    \n",
    "list_of_progressive_params = [\n",
    "                              {'objective': ['binary:logistic','reg:linear'],'learning_rate':[0.1,0.3]},\n",
    "                              {'n_estimators':np.arange(200,500,100)},\n",
    "                              {'scale_pos_weight':np.arange(2,6,1)},\n",
    "                              {'max_depth':np.arange(1,10,2),'min_child_weight':np.arange(1,10,2)},\n",
    "                              {'gamma':np.arange(0,0.5,0.1)},\n",
    "                              {'subsample':np.arange(0.6,1,0.1),'colsample_bytree':np.arange(0.6,1,0.1)},\n",
    "                              {'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]}\n",
    "                   ]\n",
    "\n",
    "model_with_name = ('xgbost', xgb.XGBClassifier)\n",
    "\n",
    "best_params_xgboost = find_best_params(df_users,df_y,model_with_name,columnas_a_mano,{}, list_of_progressive_params) \n",
    "best_params_xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "    \n",
    "list_of_progressive_params = [\n",
    "                              {'n_neighbors': np.arange(1,30)},\n",
    "                              {'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']},\n",
    "                              {'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']}\n",
    "                   ]\n",
    "\n",
    "model_with_name = ('knn', KNeighborsClassifier)\n",
    "\n",
    "best_params_knn = find_best_params(df_users, df_y, model_with_name, columnas_a_mano, {},list_of_progressive_params, seed=-1) \n",
    "best_params_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM\n",
    "\n",
    "> https://www.kaggle.com/sz8416/simple-bayesian-optimization-for-lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb #conda install -c conda-forge lightgbm \n",
    "\n",
    "list_of_progressive_params = [\n",
    "                             {'num_leaves': np.arange(24, 45)},\n",
    "                             {'feature_fraction': np.arange(0.1, 0.9)},   \n",
    "                             {'bagging_fraction': np.arange(0.8, 1)},\n",
    "                             {'max_depth': np.arange(5, 9)},\n",
    "                             {'lambda_l1': np.arange(0, 5)},\n",
    "                             {'lambda_l2': np.arange(0, 3)},\n",
    "                             {'min_split_gain': np.arange(0.001, 0.1)},\n",
    "                             {'min_child_weight': np.arange(5, 50)}\n",
    "                             ]\n",
    "    \n",
    "model_with_name = ('lightgbm', lgb.LGBMClassifier)\n",
    "\n",
    "best_params_lightgbm= find_best_params(df_users,df_y,model_with_name,columnas_a_mano,{}, list_of_progressive_params) \n",
    "best_params_lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost\n",
    "\n",
    "> https://tech.yandex.com/catboost/doc/dg/concepts/parameter-tuning-docpage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb #conda install -c conda-forge catboost \n",
    "\n",
    "list_of_progressive_params = [{'random_strength':[42],'eval_metric':['AUC'],'iterations': [100,256,465,678,1000]},\n",
    "                             {'learning_rate':[0.01,0.05,0.1,0.3]},\n",
    "                             {'depth':np.arange(1,11,5)},\n",
    "                             {'l2_leaf_reg':np.arange(2,10,3)},\n",
    "                             ]\n",
    "\n",
    "model_with_name = ('catboost', cb.CatBoostClassifier)\n",
    "\n",
    "best_params_catboost = find_best_params(df_users,df_y,model_with_name,columnas_a_mano,{'verbose':True}, list_of_progressive_params, cv=2) \n",
    "best_params_catboost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "> https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "> https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC  \n",
    "\n",
    "list_of_progressive_params = [\n",
    "                             {'max_leaf_nodes': [None]},\n",
    "                             {'min_weight_fraction_leaf': [0]},\n",
    "                             {'learning_rate': [0.1]},\n",
    "                             {'min_samples_split': np.linspace(0.1, 1.0, 10, endpoint=True)},\n",
    "                             {'min_samples_leaf': np.linspace(0.1, 0.5, 5, endpoint=True)},  \n",
    "                             {'max_features' : list(range(1,len(columnas_a_mano)))},\n",
    "                             {'max_depth': np.linspace(1, 32, 32, endpoint=True)},\n",
    "                             {'n_estimators': [1, 2, 4, 8, 16, 32, 64, 100, 20]},\n",
    "                             {'subsample': np.arange(0.8, 1)},\n",
    "                             {'loss': ['deviance']},\n",
    "                             {'warm_start': [False]},\n",
    "                             {'presort': ['auto']}\n",
    "                             ]\n",
    "    \n",
    "model_with_name = ('gradient_boosting', GBC)\n",
    "\n",
    "best_params_boosting= find_best_params(df_users,df_y,model_with_name,columnas_a_mano, list_of_progressive_params) \n",
    "best_params_boosting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Contenido",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.867px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
