{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [75.06 / 95.58] Organización de Datos <br> Trabajo Práctico 2: Machine Learning\n",
    "# Notebook Principal\n",
    "\n",
    "**Grupo 30: Datatouille**\n",
    "\n",
    "- 101055 - Bojman, Camila\n",
    "- 100029 - del Mazo, Federico\n",
    "- 100687 - Hortas, Cecilia\n",
    "- 97649 - Souto, Rodrigo\n",
    "\n",
    "**http://fdelmazo.github.io/7506-Datos/**\n",
    "\n",
    "**https://www.kaggle.com/datatouille2018/competitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando la investigación sobre la empresa Trocafone realizada en el [TP1](https://fdelmazo.github.io/7506-Datos/TP1/TP1.html), se busca determinar la probabilidad de que un usuario del sitio realice una conversión en el período determinado.\n",
    "\n",
    "Notebooks en orden de corrida y lectura:\n",
    "\n",
    "0. [TP1](https://fdelmazo.github.io/7506-Datos/TP1/TP1.html) --> Familiarización con el set de datos y exploración de estos.\n",
    "\n",
    "1. [Investigación Previa](https://fdelmazo.github.io/7506-Datos/TP2/investigacion.html) --> Con ayuda de lo trabajado en el TP1, se averiguan más cosas de las datos, en busqueda de que poder reutilizar.\n",
    "\n",
    "2. [Creación de Dataframes](https://fdelmazo.github.io/7506-Datos/TP2/new_dataframes.html) --> Como parte del feature engineering, se crean dataframes nuevos con información de los productos del sitio y de como se accede a este (marcas, sistemas operativos, etc).\n",
    "\n",
    "3. [Feature Engineering](https://fdelmazo.github.io/7506-Datos/TP2/feature_engineering.html) --> Busqueda de atributos de los usuarios de los cuales se busca predecir la conversión.\n",
    "\n",
    "4. [Submission Framework](https://fdelmazo.github.io/7506-Datos/TP2/submission_framework.html) --> Pequeño framework para construir las postulaciones de labels. \n",
    "\n",
    "5. [Parameter Tuning](https://fdelmazo.github.io/7506-Datos/TP2/parameter_tuning.html) --> Busqueda de los mejores hiper-parametros para cada algoritmo de ML.\n",
    "\n",
    "6. [Feature Selection](https://fdelmazo.github.io/7506-Datos/TP2/feature_selection.html) --> Busqueda de la combinación de features más favorable.\n",
    "\n",
    "7. TP2 (este notebook)--> Teniendo todo en cuenta, usando los dataframes con todos los atributos buscados y encontrados, se definen y aplican los algoritmos de clasificación, se realizan los entrenamientos y posteriores predicciones de conversiones y finalmente se arman las postulaciones de labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Antes de comenzar, setear las credenciales (usuario y token)**\n",
    "1. Visitar: https://www.kaggle.com/datatouille2018/account (con la cuenta que sea)\n",
    "2. Tocar en Create New API Token\n",
    "3. Guardar el archivo descargado en ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -q data/events_up_to_01062018.zip -d data\n",
    "\n",
    "# !pip install kaggle\n",
    "# !pip install nbimporter\n",
    "# !conda install -y -c conda-forge xgboost \n",
    "# !conda install -y -c conda-forge lightgbm \n",
    "# !conda install -y -c conda-forge catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter # pip install nbimporter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import calendar\n",
    "from itertools import combinations\n",
    "import random\n",
    "from time import sleep\n",
    "from parameter_tuning import get_hiper_params\n",
    "from feature_selection import get_feature_selection\n",
    "import submission_framework as SF\n",
    "\n",
    "seed = 42\n",
    "hiper_params = get_hiper_params()\n",
    "feature_selection = get_feature_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('data/user-features.csv',low_memory=False).set_index('person')\n",
    "df_y = pd.read_csv('data/labels_training_set.csv').groupby('person').sum()\n",
    "\n",
    "display(df_users.head(), df_y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posibilidades_algoritmos = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "model_name = 'decision_tree'\n",
    "params = hiper_params[model_name]\n",
    "model = DecisionTreeClassifier(**params,random_state=seed)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_name = 'random_forest'\n",
    "params = hiper_params[model_name]\n",
    "model = RandomForestClassifier(**params,random_state=seed)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb #conda install -c conda-forge xgboost \n",
    "\n",
    "model_name = 'xgboost'\n",
    "params = hiper_params[model_name]\n",
    "model = xgb.XGBClassifier(**params,random_state=seed)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_name = 'logistic_regresion'\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_name = 'knn'\n",
    "params = hiper_params[model_name]\n",
    "K = params['n_neighbors']\n",
    "model_name = f'KNN{K}'\n",
    "\n",
    "model = KNeighborsClassifier(**params)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB,MultinomialNB,ComplementNB\n",
    "\n",
    "model_name = 'naive_bayes_Gaussian'\n",
    "model = GaussianNB(**{'var_smoothing': 1e-09})\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "posibilidades_algoritmos.append(model_with_name)\n",
    "\n",
    "model_name = 'naive_bayes_Bernoulli'\n",
    "model = BernoulliNB()\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "posibilidades_algoritmos.append(model_with_name)\n",
    "\n",
    "model_name = 'naive_bayes_Multinomial'\n",
    "model = MultinomialNB()\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "posibilidades_algoritmos.append(model_with_name)\n",
    "\n",
    "model_name = 'naive_bayes_Complement'\n",
    "model = ComplementNB()\n",
    "model_with_name = (model_name,model)\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb  #conda install -c conda-forge lightgbm \n",
    "\n",
    "model_name = 'lightgbm'\n",
    "params = hiper_params[model_name]\n",
    "model = lgb.LGBMClassifier(**params)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_name = 'neuralnetwork'\n",
    "params = hiper_params[model_name]\n",
    "model = MLPClassifier(**params)\n",
    "model_with_name = (model_name, model)\n",
    "\n",
    "# Funciona sólo con datos normalizados\n",
    "SF.full_framework_wrapper(df_users, df_y, model_with_name, normalize=True)\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import catboost as cb #conda install -c conda-forge catboost\n",
    "\n",
    "# model_name = 'catboost'\n",
    "# params = hiper_params[model_name]\n",
    "\n",
    "# model = cb.CatBoostClassifier(**params,verbose=False)\n",
    "# model_with_name = (model_name,model)\n",
    "\n",
    "# SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "# posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC  \n",
    "\n",
    "model_name = 'gradient_boosting'\n",
    "params = hiper_params[model_name]\n",
    "\n",
    "model = GBC(**params)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Encontrando el mejor submit\n",
    "\n",
    "Corremos todos los algoritmos definidos sobre esas combinaciones, incluso ensamblados, en busqueda de su mejor combinación de hiper-parametros.\n",
    "\n",
    "Finalmente, se corren todos los algoritmos en su mejor combinación contra todos los set de features definidos, en busqueda de la mejor fusión universal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todos los posibles algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x[0] for x in posibilidades_algoritmos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "EXCLUDED = ['catboost','neuralnetwork',f'KNN{K}']\n",
    "\n",
    "def bagging(posibilidades):\n",
    "    posibilidades = list(filter(lambda x:x[0] not in EXCLUDED,posibilidades)) # Tarda muchísimo un ensamble con catboost\n",
    "    baggins = [] # Frodo\n",
    "    for n,m in posibilidades:\n",
    "        baggins.append((n+'_bagging',BaggingClassifier(m)))\n",
    "    return baggins\n",
    "\n",
    "posibilidades_algoritmos_y_ensambles = posibilidades_algoritmos + bagging(posibilidades_algoritmos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUDED = ['catboost','neuralnetwork']\n",
    "\n",
    "def ensamblar_algoritmos(posibilidades, n):\n",
    "    posibilidades = list(filter(lambda x:x[0] not in EXCLUDED,posibilidades)) # Tarda muchísimo un ensamble con catboost\n",
    "    result = list(combinations(posibilidades,n))\n",
    "    result_names = [f'{x[0][0]}+{x[1][0]}' for x in result]\n",
    "    return list(zip(result_names,result))\n",
    "\n",
    "posibilidades_algoritmos_y_ensambles += ensamblar_algoritmos(posibilidades_algoritmos,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensamble_tres_a_mano(nombre1,nombre2,nombre3):\n",
    "    result = list(combinations(posibilidades_algoritmos, 3))\n",
    "    for r in result:\n",
    "        names = [x[0] for x in r]\n",
    "        if nombre1 in names and nombre2 in names and nombre3 in names:\n",
    "            result_names = '+'.join(names)\n",
    "            return (result_names,r)\n",
    "        \n",
    "#posibilidades_algoritmos_y_ensambles += [ensamble_tres_a_mano()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x[0] for x in posibilidades_algoritmos_y_ensambles])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todos los posibles sets de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posibilidades_features = {\n",
    "#     'Cumulative Importance':feature_selection['best_features_progresivo'],\n",
    "#     'Forward Selection':feature_selection['best_features_forward'],\n",
    "    'Backward Elimination':feature_selection['best_features_backward'],\n",
    "#     'Stepwise Regression ':feature_selection['best_features_stepwise'],\n",
    "#     'Full Dataframe':[],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo_junto = [x for f in posibilidades_features.values() for x in f]\n",
    "intersec = list(set([x for x in todo_junto if todo_junto.count(x)>=2]))\n",
    "# posibilidades_features['Feature Intersection'] = intersec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posibilidades_features['Seleccion a Mano'] = ['total_checkouts_month_5',\n",
    "#                     'timestamp_last_checkout',\n",
    "#                     'timestamp_last_event',\n",
    "#                     'has_checkout_month_5',\n",
    "#                     'total_checkouts',\n",
    "#                     'days_to_last_event',\n",
    "#                     'total_checkouts_last_week',\n",
    "#                     'total_checkouts_months_1_to_4',\n",
    "#                     'total_conversions',\n",
    "#                     'total_session_conversion',\n",
    "#                     'total_events',\n",
    "#                     'total_sessions',\n",
    "#                     'avg_events_per_session',\n",
    "#                     'total_session_checkout',\n",
    "#                     'has_checkout'\n",
    "#                     ]\n",
    "\n",
    "# posibilidades_features['Seleccion a Mano 2'] = ['dow_last_conversion', \n",
    "#                      'has_conversion_last_week', 'total_conversions_month_4', \n",
    "#                      'total_session_checkout', 'doy_last_conversion', 'timestamp_last_event', \n",
    "#                      'dow_last_checkout', 'total_checkouts', 'has_checkout', 'doy_last_checkout', \n",
    "#                      'has_checkout_month_1', 'timestamp_last_checkout', 'total_sessions', \n",
    "#                      'woy_last_event', 'has_checkout_month_5', 'avg_events_per_session']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cant_features = 30\n",
    "\n",
    "# posibilidades_features[f'{cant_features} Random Sample'] = random.sample(df_users.columns.tolist(),cant_features)\n",
    "# posibilidades_features[f'{cant_features} Random Sample 2'] = random.sample(df_users.columns.tolist(),cant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x for x in posibilidades_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Combinando ambas ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "global_time = 0\n",
    "\n",
    "for forma, features in posibilidades_features.items():\n",
    "    global_start = time.process_time()\n",
    "    print(\"\\nTardó: {: ^100}s\\n{: ^100s}\".format(round(global_time,2),'-----------------------'))\n",
    "    print(f'{forma}:\\n')\n",
    "    print(f'{features}\\n\\n')\n",
    "    for nombre,algoritmo in posibilidades_algoritmos_y_ensambles:\n",
    "        print('\\t * ',end='')\n",
    "        model_with_name = (f'{nombre}',algoritmo)\n",
    "        start = time.process_time()\n",
    "        model, auc = SF.full_framework_wrapper(df_users, df_y, model_with_name, columns=features)\n",
    "        end = time.process_time()\n",
    "        print(f'\\t\\t Tardó: {end-start:.2f}s')\n",
    "        resultados.append((auc, forma, (nombre, algoritmo), features))\n",
    "    global_end = time.process_time()\n",
    "    global_start = global_end-global_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.sort(reverse=True)\n",
    "display([(x[0],x[1],x[2][0]) for x in resultados])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrida Final\n",
    "\n",
    "Se corre entrenando con X (y no X_train) el submit final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_auc, campeon_forma, (campeon_nombre, campeon_algoritmo), campeon_features = resultados[1]\n",
    "display(f\"Mejor Apuesta: {campeon_nombre} ({max_auc:.4f} AUC) - Features: {campeon_forma}\")\n",
    "display(f\"Features: {campeon_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{campeon_nombre} - {campeon_forma} - {max_auc:.4f}\")\n",
    "campeon_model, campeon_auc, csv_name, campeon_message = SF.full_framework_wrapper(df_users, \n",
    "                                                                                    df_y, \n",
    "                                                                                    (campeon_nombre,campeon_algoritmo),\n",
    "                                                                                    columns=campeon_features,\n",
    "                                                                                    submit=True,\n",
    "                                                                                    all_in=True)   \n",
    "\n",
    "#!kaggle competitions submit -f {csv_name} -m \"{campeon_message}\" trocafone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quemar n submits de punta a punta \n",
    "\n",
    "# for resultado in (resultados[1],resultados[2],resultados[5],resultados[6]):\n",
    "#     print(f\"\\n\\n{resultado[2][0]} - {resultado[1]} - {resultado[0]:.4f}\\n\\n)\n",
    "#     max_auc, campeon_forma, (campeon_nombre, campeon_algoritmo), campeon_features = resultado\n",
    "#     campeon_model, campeon_auc, csv_name, campeon_message = SF.full_framework_wrapper(df_users, \n",
    "#                                                                                     df_y, \n",
    "#                                                                                     (campeon_nombre,campeon_algoritmo),\n",
    "#                                                                                     columns=campeon_features,\n",
    "#                                                                                     submit=True,\n",
    "#                                                                                     all_in=True)   \n",
    "#     !kaggle competitions submit -f {csv_name} -m \"{campeon_message}\" trocafone\n",
    "#     sleep(10)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions leaderboard -d trocafone\n",
    "#!unzip -o trocafone.zip\n",
    "#print('Last Best Score')\n",
    "#!cat trocafone-publicleaderboard.csv | grep Datatouille | tail -n 1 | awk '{split($0,a,\",\"); print \"\\t Fecha: \" a[3] ; print \"\\t Porcentaje: \" a[4]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/trocafone/submissions?sortBy=date\n",
    "\n",
    "https://www.kaggle.com/c/trocafone/leaderboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Contenido",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.867px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
