{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [75.06 / 95.58] Organización de Datos <br> Trabajo Práctico 2: Machine Learning\n",
    "# Notebook Principal\n",
    "\n",
    "**Grupo 30: Datatouille**\n",
    "\n",
    "- 101055 - Bojman, Camila\n",
    "- 100029 - del Mazo, Federico\n",
    "- 100687 - Hortas, Cecilia\n",
    "- 97649 - Souto, Rodrigo\n",
    "\n",
    "**http://fdelmazo.github.io/7506-Datos/**\n",
    "\n",
    "**https://www.kaggle.com/datatouille2018/competitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando la investigación sobre la empresa Trocafone realizada en el [TP1](https://fdelmazo.github.io/7506-Datos/TP1/TP1.html), se busca determinar la probabilidad de que un usuario del sitio realice una conversión en el período determinado.\n",
    "\n",
    "Notebooks en orden de corrida y lectura:\n",
    "\n",
    "0. [TP1](https://fdelmazo.github.io/7506-Datos/TP1/TP1.html) --> Familiarización con el set de datos y exploración de estos.\n",
    "\n",
    "1. [Investigación Previa](https://fdelmazo.github.io/7506-Datos/TP2/investigacion.html) --> Con ayuda de lo trabajado en el TP1, se averiguan más cosas de las datos, en busqueda de que poder reutilizar.\n",
    "\n",
    "2. [Creación de Dataframes](https://fdelmazo.github.io/7506-Datos/TP2/new_dataframes.html) --> Como parte del feature engineering, se crean dataframes nuevos con información de los productos del sitio y de como se accede a este (marcas, sistemas operativos, etc).\n",
    "\n",
    "3. [Feature Engineering](https://fdelmazo.github.io/7506-Datos/TP2/feature_engineering.html) --> Busqueda de atributos de los usuarios de los cuales se busca predecir la conversión.\n",
    "\n",
    "4. [Submission Framework](https://fdelmazo.github.io/7506-Datos/TP2/submission_framework.html) --> Pequeño framework para construir las postulaciones de labels. \n",
    "\n",
    "5. [Parameter Tuning](https://fdelmazo.github.io/7506-Datos/TP2/parameter_tuning.html) --> Busqueda de los mejores hiper-parametros para cada algoritmo de ML.\n",
    "\n",
    "6. [Feature Selection](https://fdelmazo.github.io/7506-Datos/TP2/feature_selection.html) --> Busqueda de la combinación de features más favorable.\n",
    "\n",
    "7. TP2 (este notebook)--> Teniendo todo en cuenta, usando los dataframes con todos los atributos buscados y encontrados, se definen y aplican los algoritmos de clasificación, se realizan los entrenamientos y posteriores predicciones de conversiones y finalmente se arman las postulaciones de labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up inicial, se deja comentado para evitar instalarle módulos al usuario\n",
    "## Primero, descargar los datasets de no tenerlos\n",
    "\n",
    "# Antes de comenzar, setear las credenciales (usuario y token)\n",
    "\n",
    "# 1. Visitar: https://www.kaggle.com/datatouille2018/account (con la cuenta que sea)\n",
    "# 2. Tocar en Create New API Token\n",
    "# 3. Guardar el archivo descargado en ~/.kaggle/kaggle.json\n",
    "\n",
    "# !pip install kaggle # https://github.com/Kaggle/kaggle-api\n",
    "# !kaggle competitions download -c trocafone -p data\n",
    "# !unzip -q data/events_up_to_01062018.csv.zip -d data\n",
    "# !rm data/events_up_to_01062018.csv.zip\n",
    "# !ls data/\n",
    "\n",
    "## Luego, descargar los módulos a utilizar a lo largo de todo el trabajo\n",
    "\n",
    "# !pip install nbimporter\n",
    "# !conda install -c conda-forge xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter # pip install nbimporter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "from parameter_tuning import get_hiper_params\n",
    "from feature_selection import get_feature_selection\n",
    "import submission_framework as SF\n",
    "\n",
    "seed = 42\n",
    "hiper_params = get_hiper_params()\n",
    "feature_selection = get_feature_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('data/user-features.csv',low_memory=False).set_index('person')\n",
    "df_y = pd.read_csv('data/labels_training_set.csv').groupby('person').sum()\n",
    "\n",
    "display(df_users.head(), df_y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posibilidades_algoritmos = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "model_name = 'decision_tree'\n",
    "params = hiper_params[model_name]\n",
    "model = DecisionTreeClassifier(**params,random_state=seed)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_name = 'random_forest'\n",
    "params = hiper_params[model_name]\n",
    "model = RandomForestClassifier(**params,random_state=seed)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb #conda install -c conda-forge xgboost \n",
    "\n",
    "model_name = 'xgboost'\n",
    "params = hiper_params[model_name]\n",
    "model = xgb.XGBClassifier(**params,random_state=seed)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_name = 'knn'\n",
    "params = hiper_params[model_name]\n",
    "K = params['n_neighbors']\n",
    "model_name = f'KNN{K}'\n",
    "\n",
    "model = KNeighborsClassifier(**params)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "model_name = 'naive_bayes'\n",
    "params = hiper_params[model_name]\n",
    "model = GaussianNB(**params)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Encontrando el mejor submit\n",
    "\n",
    "Corremos todos los algoritmos definidos sobre esas combinaciones, en busqueda de su mejor combinación de hiper-parametros.\n",
    "\n",
    "Finalmente, se corren todos los algoritmos en su mejor combinación contra todos los set de features definidos, en busqueda de la mejor fusión universal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_mano = ['total_checkouts_month_5',\n",
    "                    'timestamp_last_checkout',\n",
    "                    'timestamp_last_event',\n",
    "                    'has_checkout_month_5',\n",
    "                    'total_checkouts',\n",
    "                    'days_to_last_event',\n",
    "                    'total_checkouts_last_week',\n",
    "                    'total_checkouts_months_1_to_4',\n",
    "                    'total_conversions',\n",
    "                    'total_session_conversions',\n",
    "                    'total_events',\n",
    "                    'total_sessions',\n",
    "                    'avg_events_per_session',\n",
    "                    'total_session_checkouts',\n",
    "                    'has_checkout'\n",
    "                    ]\n",
    "\n",
    "columnas_a_mano_2 = ['dow_last_conversion', \n",
    "                     'has_conversion_last_week', 'total_conversions_month_4', \n",
    "                     'total_session_checkouts', 'doy_last_conversion', 'timestamp_last_event', \n",
    "                     'dow_last_checkout', 'total_checkouts', 'has_checkout', 'doy_last_checkout', \n",
    "                     'has_checkout_month_1', 'timestamp_last_checkout', 'total_sessions', \n",
    "                     'woy_last_event', 'has_checkout_month_5', 'avg_events_per_session']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posibilidades_features = {\n",
    "    'Full Dataframe':None,\n",
    "    'Best Cumulative Importance':feature_selection['best_features_progresivo'],\n",
    "    'Best Forward Selection':feature_selection['best_features_forward'],\n",
    "    'Best Backward Elimination':feature_selection['best_features_backward'],\n",
    "    'Leap Cumulative Importance':feature_selection['features_con_saltos_progresivo'],\n",
    "    'Leap Forward Selection':feature_selection['features_con_saltos_forward'],\n",
    "    'Selección a Mano': columnas_a_mano,\n",
    "    'Selección a Mano 2': columnas_a_mano_2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_auc = 0\n",
    "campeon_nombre = ''\n",
    "campeon_algoritmo = None\n",
    "campeon_forma = None\n",
    "campeon_features = None\n",
    "\n",
    "es_ensamble = False\n",
    "\n",
    "for nombre,algoritmo in posibilidades_algoritmos:\n",
    "    for forma, features in posibilidades_features.items():\n",
    "        model_with_name = (f'{forma} - {nombre}',algoritmo)\n",
    "        model, auc = SF.full_framework_wrapper(df_users, df_y, model_with_name, columns=features)\n",
    "        if auc > max_auc:\n",
    "            max_auc = auc\n",
    "            campeon_nombre = nombre\n",
    "            campeon_algoritmo = algoritmo\n",
    "            campeon_forma = forma\n",
    "            campeon_features = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(f\"Mejor Apuesta (so far): {campeon_nombre} ({max_auc:.4f} AUC) - Features: {campeon_forma}\")\n",
    "display(f\"Features: {campeon_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensambles de algoritmos\n",
    "\n",
    "Se prueban todas las posibilidades de combinación de 2 algoritmos y se queda con la que arroje mejor AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "                             \n",
    "def obtain_combinations(n):\n",
    "    result = list(combinations(posibilidades_algoritmos, n))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "algorithm_combinations = obtain_combinations(2)\n",
    "\n",
    "for combinacion_algoritmo in algorithm_combinations:\n",
    "    for forma, features in posibilidades_features.items():\n",
    "        print(f'{forma} - ',end='')\n",
    "        model, auc = SF.full_framework_ensemble_wrapper(df_users, df_y, combinacion_algoritmo, columns=features)\n",
    "        if auc > max_auc:\n",
    "            es_ensamble=True\n",
    "            max_auc = auc\n",
    "            campeon_algoritmo = combinacion_algoritmo\n",
    "            campeon_forma = forma\n",
    "            campeon_features = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if es_ensamble: campeon_nombre = f\"{'+'.join([x[0] for x in campeon_algoritmo])}\"\n",
    "display(f\"Mejor Apuesta: {campeon_nombre} ({max_auc:.4f} AUC) - Features: {campeon_forma}\")\n",
    "display(f\"Features: {campeon_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrida Final\n",
    "\n",
    "Se corre entrenando con X (y no X_train) el submit final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ensamble = 300\n",
    "\n",
    "if es_ensamble:\n",
    "    campeon_model, campeon_auc, csv_name, campeon_message = SF.full_framework_ensemble_wrapper(df_users, \n",
    "                                                                                                df_y, \n",
    "                                                                                                campeon_algoritmo,\n",
    "                                                                                                columns=features,\n",
    "                                                                                                n_ensamble=n_ensamble,\n",
    "                                                                                                submit=True,\n",
    "                                                                                                verbosity=1,\n",
    "                                                                                                all_in=True)\n",
    "else:\n",
    "    campeon_model, campeon_auc, csv_name, campeon_message = SF.full_framework_wrapper(df_users, \n",
    "                                                                                    df_y, \n",
    "                                                                                    (campeon_nombre,campeon_algoritmo),\n",
    "                                                                                    columns=features,\n",
    "                                                                                    n_ensamble=n_ensamble,\n",
    "                                                                                    submit=True,\n",
    "                                                                                    verbosity=1,\n",
    "                                                                                    all_in=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Descomentar y submitear!\n",
    "## Ojo, solo correr una vez!!!\n",
    "\n",
    "#!kaggle competitions submit -f {csv_name} -m \"{campeon_message}\" trocafone\n",
    "\n",
    "print()\n",
    "print('https://www.kaggle.com/c/trocafone/submissions?sortBy=date')\n",
    "print('https://www.kaggle.com/c/trocafone/leaderboard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Algoritmos y Features\n",
    "\n",
    "* Naive Bayes\n",
    "\n",
    "* Perceprton\n",
    "\n",
    "* SVM\n",
    "\n",
    "* https://github.com/urielkelman/abracadata/tree/master/TP2\n",
    "\n",
    "* https://github.com/MatiasReimondo/Datos\n",
    "\n",
    "\n",
    "## Lista de cosas que se pueden hacer\n",
    "\n",
    "* [ ] Identificar bias y varianza, ploteando error de set de entrenamiento y error de set de test en funcion de cantidad de datos en set de entrenamiento (mismo plot)\n",
    "\n",
    "* [ ] Perturbar datos de entrada -> reducir overfitting\n",
    "\n",
    "* [ ] Plotear AUC nuestra, AUC kaggle segun submission\n",
    "\n",
    "* [ ] Catboost\n",
    "\n",
    "* [ ] Reclamar 50 usd aws &#128544; \n",
    "\n",
    "* [ ] Clustering para nuevos features para entrenar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Contenido",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.867px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
