{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [75.06 / 95.58] Organización de Datos <br> Trabajo Práctico 2: Machine Learning\n",
    "# Notebook Principal\n",
    "\n",
    "**Grupo 30: Datatouille**\n",
    "\n",
    "- 101055 - Bojman, Camila\n",
    "- 100029 - del Mazo, Federico\n",
    "- 100687 - Hortas, Cecilia\n",
    "- 97649 - Souto, Rodrigo\n",
    "\n",
    "**http://fdelmazo.github.io/7506-Datos/**\n",
    "\n",
    "**https://www.kaggle.com/datatouille2018/competitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando la investigación sobre la empresa Trocafone realizada en el [TP1](https://fdelmazo.github.io/7506-Datos/TP1/TP1.html), se busca determinar la probabilidad de que un usuario del sitio realice una conversión en el período determinado.\n",
    "\n",
    "Notebooks en orden de corrida y lectura:\n",
    "\n",
    "0. [TP1](https://fdelmazo.github.io/7506-Datos/TP1/TP1.html) --> Familiarización con el set de datos y exploración de estos.\n",
    "\n",
    "1. [Investigación Previa](https://fdelmazo.github.io/7506-Datos/TP2/investigacion.html) --> Con ayuda de lo trabajado en el TP1, se averiguan más cosas de las datos, en busqueda de que poder reutilizar.\n",
    "\n",
    "2. [Creación de Dataframes](https://fdelmazo.github.io/7506-Datos/TP2/new_dataframes.html) --> Como parte del feature engineering, se crean dataframes nuevos con información de los productos del sitio y de como se accede a este (marcas, sistemas operativos, etc).\n",
    "\n",
    "3. [Feature Engineering](https://fdelmazo.github.io/7506-Datos/TP2/feature_engineering.html) --> Busqueda de atributos de los usuarios de los cuales se busca predecir la conversión.\n",
    "\n",
    "4. [Submission Framework](https://fdelmazo.github.io/7506-Datos/TP2/submission_framework.html) --> Pequeño framework para construir las postulaciones de labels. \n",
    "\n",
    "5. [Parameter Tuning](https://fdelmazo.github.io/7506-Datos/TP2/parameter_tuning.html) --> Busqueda de los mejores hiper-parametros para cada algoritmo de ML.\n",
    "\n",
    "6. [Feature Selection](https://fdelmazo.github.io/7506-Datos/TP2/feature_selection.html) --> Busqueda de la combinación de features más favorable.\n",
    "\n",
    "7. TP2 (este notebook)--> Teniendo todo en cuenta, usando los dataframes con todos los atributos buscados y encontrados, se definen y aplican los algoritmos de clasificación, se realizan los entrenamientos y posteriores predicciones de conversiones y finalmente se arman las postulaciones de labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up inicial, se deja comentado para evitar instalarle módulos al usuario\n",
    "## Primero, descargar los datasets de no tenerlos\n",
    "\n",
    "# Antes de comenzar, setear las credenciales (usuario y token)\n",
    "\n",
    "# 1. Visitar: https://www.kaggle.com/datatouille2018/account (con la cuenta que sea)\n",
    "# 2. Tocar en Create New API Token\n",
    "# 3. Guardar el archivo descargado en ~/.kaggle/kaggle.json\n",
    "\n",
    "# !pip install kaggle # https://github.com/Kaggle/kaggle-api\n",
    "# !kaggle competitions download -c trocafone -p data\n",
    "# !unzip -q data/events_up_to_01062018.csv.zip -d data\n",
    "# !rm data/events_up_to_01062018.csv.zip\n",
    "# !ls data/\n",
    "\n",
    "## Luego, descargar los módulos a utilizar a lo largo de todo el trabajo\n",
    "\n",
    "# !pip install nbimporter\n",
    "# !conda install -c conda-forge xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter # pip install nbimporter\n",
    "nbimporter.options['only_defs'] = False\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import parameter_tuning as hiper_params\n",
    "import feature_selection as feature_selection\n",
    "import submission_framework as SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('data/user-features.csv',low_memory=False).set_index('person')\n",
    "df_y = pd.read_csv('data/labels_training_set.csv').groupby('person').sum()\n",
    "\n",
    "display(df_users.head(), df_y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "bp_dt = hiper_params.best_params_decision_tree\n",
    "\n",
    "def decision_tree(X_train, y_train, seed, params=bp_dt):\n",
    "    tree = DecisionTreeClassifier(**params,random_state=seed)\n",
    "    tree.fit(X_train, y_train)\n",
    "    return tree\n",
    "\n",
    "model, auc = SF.full_framework_wrapper('decision_tree',decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "bp_rf = hiper_params.best_params_random_forest\n",
    "\n",
    "def random_forest(X_train, y_train, seed, params=bp_rf):\n",
    "    rf = RandomForestClassifier(**params,random_state=seed)\n",
    "    y_train.shape = y_train.shape[0]\n",
    "    rf.fit(X_train, y_train)\n",
    "    return rf\n",
    "\n",
    "SF.full_framework_wrapper('random_forest',random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb #conda install -c conda-forge xgboost \n",
    "\n",
    "bp_xg = hiper_params.best_params_xgboost\n",
    "\n",
    "def xgboost(X_train, y_train, seed, params=bp_xg):\n",
    "    xg_reg = xgb.XGBClassifier(**params,random_state=seed)\n",
    "    y_train.shape = y_train.shape[0]\n",
    "    xg_reg.fit(X_train,y_train)\n",
    "    return xg_reg\n",
    "\n",
    "SF.full_framework_wrapper('xgboost',xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "bp_knn = hiper_params.best_params_knn\n",
    "K = bp_knn['n_neighbors']\n",
    "\n",
    "def knn(X_train, y_train, seed, params=bp_knn):\n",
    "    knn = KNeighborsClassifier(**params)\n",
    "    y_train.shape = y_train.shape[0]\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn\n",
    "\n",
    "SF.full_framework_wrapper(f'KNN{K}',knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Encontrando el mejor submit\n",
    "\n",
    "Corremos todos los algoritmos definidos sobre esas combinaciones, en busqueda de su mejor combinación de hiper-parametros.\n",
    "\n",
    "Finalmente, se corren todos los algoritmos en su mejor combinación contra todos los set de features definidos, en busqueda de la mejor fusión universal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_mano = ['total_checkouts_month_5',\n",
    "'timestamp_last_checkout',\n",
    "'timestamp_last_event',\n",
    "'has_checkout_month_5',\n",
    "'total_checkouts',\n",
    "'days_to_last_event',\n",
    "'total_checkouts_last_week',\n",
    "'total_checkouts_months_1_to_4',\n",
    "'total_conversions',\n",
    "'total_session_conversions',\n",
    "'total_events',\n",
    "'total_sessions',\n",
    "'avg_events_per_session',\n",
    "'total_session_checkouts',\n",
    "'has_checkout'\n",
    "]\n",
    "\n",
    "columnas_a_mano_2 = ['dow_last_conversion', 'has_conversion_last_week', 'total_conversions_month_4', 'total_session_checkouts', 'doy_last_conversion', 'timestamp_last_event', 'dow_last_checkout', 'total_checkouts', 'has_checkout', 'doy_last_checkout', 'has_checkout_month_1', 'timestamp_last_checkout', 'total_sessions', 'woy_last_event', 'has_checkout_month_5', 'avg_events_per_session']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posibilidades_features = {\n",
    "    'Best Cumulative Importance':feature_selection.best_features_progresivo,\n",
    "    'Best Forward Selection':feature_selection.best_features_forward,\n",
    "    'Best Backward Elimination':feature_selection.best_features_backward,\n",
    "    'Leap Cumulative Importance':feature_selection.features_con_saltos_progresivo,\n",
    "    'Leap Forward Selection':feature_selection.features_con_saltos_forward,\n",
    "    'Selección a Mano': columnas_a_mano,\n",
    "    'Selección a Mano 2': columnas_a_mano_2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posibilidades_algoritmos = [('xgboost',xgboost),\n",
    "                 ('random_forest',random_forest),\n",
    "                 ('decision_tree',decision_tree),\n",
    "                 (f'KNN{K}',knn)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_auc = 0\n",
    "campeon_nombre = ''\n",
    "campeon_algoritmo = None\n",
    "campeon_forma = None\n",
    "campeon_features = None\n",
    "\n",
    "for nombre,algoritmo in posibilidades_algoritmos:\n",
    "    for forma, features in posibilidades_features.items():\n",
    "        model, auc = SF.full_framework_wrapper(f'{forma} - {nombre}',algoritmo,columns=features)\n",
    "        if auc > max_auc:\n",
    "            max_auc = auc\n",
    "            campeon_nombre = nombre\n",
    "            campeon_algoritmo = algoritmo\n",
    "            campeon_forma = forma\n",
    "            campeon_features = features\n",
    "            \n",
    "display(f\"Mejor Apuesta: {campeon_nombre} ({max_auc:.2f} AUC) - Features: {campeon_forma}\")\n",
    "display(f\"Features: {campeon_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrida Final\n",
    "\n",
    "Se corre entrenando con X (y no X_train) el submit final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ensamble = 300\n",
    "\n",
    "campeon_model, campeon_auc, csv_name, campeon_message = SF.full_framework_wrapper(campeon_nombre,\n",
    "                       campeon_algoritmo,\n",
    "                       columns=campeon_features,\n",
    "                       ensamble=n_ensamble,\n",
    "                       submit=True,\n",
    "                       verbosity=1,\n",
    "                       all_in=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Descomentar y submitear!\n",
    "## Ojo, solo correr una vez!!!\n",
    "\n",
    "!kaggle competitions submit -f {csv_name} -m \"{campeon_message}\" trocafone\n",
    "\n",
    "print()\n",
    "print('https://www.kaggle.com/c/trocafone/submissions?sortBy=date')\n",
    "print('https://www.kaggle.com/c/trocafone/leaderboard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Algoritmos y Features\n",
    "\n",
    "* PRECIOS\n",
    "\n",
    "* Naive Bayes\n",
    "\n",
    "* Perceprton\n",
    "\n",
    "* SVM\n",
    "\n",
    "* https://github.com/urielkelman/abracadata/tree/master/TP2\n",
    "\n",
    "* https://github.com/MatiasReimondo/Datos\n",
    "\n",
    "\n",
    "## Lista de cosas que se pueden hacer\n",
    "\n",
    "* [ ] Identificar bias y varianza, ploteando error de set de entrenamiento y error de set de test en funcion de cantidad de datos en set de entrenamiento (mismo plot)\n",
    "\n",
    "* [ ] Perturbar datos de entrada -> reducir overfitting\n",
    "\n",
    "* [ ] Plotear AUC nuestra, AUC kaggle segun submission\n",
    "\n",
    "* [ ] Catboost\n",
    "\n",
    "* [ ] Reclamar 50 usd aws &#128544; \n",
    "\n",
    "* [ ] Clustering para nuevos features para entrenar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Contenido",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.867px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
