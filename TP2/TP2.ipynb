{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [75.06 / 95.58] Organización de Datos <br> Trabajo Práctico 2: Machine Learning\n",
    "# Notebook Principal\n",
    "\n",
    "**Grupo 30: Datatouille**\n",
    "\n",
    "- 101055 - Bojman, Camila\n",
    "- 100029 - del Mazo, Federico\n",
    "- 100687 - Hortas, Cecilia\n",
    "- 97649 - Souto, Rodrigo\n",
    "\n",
    "**http://fdelmazo.github.io/7506-Datos/**\n",
    "\n",
    "**https://www.kaggle.com/datatouille2018/competitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando la investigación sobre la empresa Trocafone realizada en el [TP1](https://fdelmazo.github.io/7506-Datos/TP1/TP1.html), se busca determinar la probabilidad de que un usuario del sitio realice una conversión en el período determinado.\n",
    "\n",
    "Notebooks en orden de corrida y lectura:\n",
    "\n",
    "0. [TP1](https://fdelmazo.github.io/7506-Datos/TP1/TP1.html) --> Familiarización con el set de datos y exploración de estos.\n",
    "\n",
    "1. [Investigación Previa](https://fdelmazo.github.io/7506-Datos/TP2/investigacion.html) --> Con ayuda de lo trabajado en el TP1, se averiguan más cosas de las datos, en busqueda de que poder reutilizar.\n",
    "\n",
    "2. [Creación de Dataframes](https://fdelmazo.github.io/7506-Datos/TP2/new-dataframes.html) --> Como parte del feature engineering, se crean dataframes nuevos con información de los productos del sitio y de como se accede a este (marcas, sistemas operativos, etc).\n",
    "\n",
    "3. [Feature Engineering](https://fdelmazo.github.io/7506-Datos/TP2/feature-engineering.html) --> Busqueda de atributos de los usuarios de los cuales se busca predecir la conversión\n",
    "\n",
    "4. [Submission Framework](https://fdelmazo.github.io/7506-Datos/TP2/submission-framework.html) --> Pequeño framework para construir las postulaciones de labels. \n",
    "\n",
    "5. Algoritmos de clasificación (directorio `AlgoritmosClasificacion`) --> Definiciones de algoritmos de machine learning para utilizar en este notebook\n",
    "\n",
    "  * [Árboles de decisión](https://fdelmazo.github.io/7506-Datos/TP2/AlgoritmosClasificacion/decision-tree.html): TODO, descr\n",
    "  * [Random Forest](https://fdelmazo.github.io/7506-Datos/TP2/AlgoritmosClasificacion/random-forest.html): TODO, descr\n",
    "  * [XGBoost](https://fdelmazo.github.io/7506-Datos/TP2/AlgoritmosClasificacion/xgboost.html): TODO, descr\n",
    "\n",
    "6. TP2 --> Teniendo todo en cuenta, juntar todos los datos buscados y encontrados sobre un mismo dataframe, aplicarle todos los algoritmos definidos previamente e ir realizando los entrenamientos y posteriores predicciones de conversiones con las que se arman las postulaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up inicial, se deja comentado para evitar instalarle módulos al usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Primero, descargar los datasets de no tenerlos\n",
    "\n",
    "# Antes de comenzar, buscar las credenciales de kaggle (el nombre de usuario, y el token) y setearlos en las siguientes dos lineas\n",
    "# %env KAGGLE_USERNAME=\"datatouille2018\"\n",
    "# %env KAGGLE_KEY=\"xxx\"\n",
    "\n",
    "# !pip install kaggle # https://github.com/Kaggle/kaggle-api\n",
    "# !kaggle competitions download -c trocafone -p data\n",
    "# !unzip -q data/events_up_to_01062018.csv.zip -d data\n",
    "# !rm data/events_up_to_01062018.csv.zip\n",
    "# !ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Luego, descargar los módulos a utilizar a lo largo de todo el trabajo\n",
    "\n",
    "# !pip install nbimporter\n",
    "# !conda install -c conda-forge xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import pandas as pd\n",
    "import calendar\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os.path\n",
    "\n",
    "from AlgoritmosClasificacion import *\n",
    "import submission_framework as SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('data/user-features.csv',low_memory=False).set_index('person')\n",
    "df_y = pd.read_csv('data/labels_training_set.csv').groupby('person').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Lista de robos\n",
    "\n",
    "TODO: Borrar\n",
    "\n",
    "* [ ] https://github.com/urielkelman/abracadata/tree/master/TP2\n",
    "\n",
    "* [ ] https://github.com/GastonMontes/Datos-TP2\n",
    "\n",
    "* [ ] https://github.com/MatiasReimondo/Datos\n",
    "\n",
    "* [ ] Ver diapos argerich feature engineering\n",
    "\n",
    "* [ ] Spammear ramos mejia de preguntas\n",
    "\n",
    "* [ ] Notebooks de Martin\n",
    "\n",
    "* [ ] Notebook de Juan\n",
    "\n",
    "## Lista de cosas a hacer\n",
    "\n",
    "* [ ] Dividir en set de entrenamientos y set de test. Ojo, hay que hacerlo con tiempo! No se puede hacer al azar. Los primeros meses entrenan a los siguientes. Etc\n",
    "\n",
    "* [ ] Identificar bias y varianza, ploteando error de set de entrenamiento y error de set de test en funcion de cantidad de datos en set de entrenamiento (mismo plot)\n",
    "\n",
    "* [ ] Perturbar datos de entrada -> reducir overfitting\n",
    "\n",
    "* [ ] Feature engineering --> no olvidar documentar y versionar!!!\n",
    "\n",
    "* [ ] Catboost\n",
    "\n",
    "* [ ] Feature: dia de la semana\n",
    "\n",
    "* [ ] Loopear interacciones importantes! Random forest claveee\n",
    "\n",
    "* [ ] No perder nombre de feature original\n",
    "\n",
    "* [ ] Scrapear trocafone --> Precios\n",
    "\n",
    "* [ ] Xgboost no sirve para importancia de features. No es estable\n",
    "\n",
    "* [ ] Reclamar 50 usd aws &#128544; \n",
    "\n",
    "* [ ] Clustering para nuevos features para entrenar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Contenido",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.867px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
