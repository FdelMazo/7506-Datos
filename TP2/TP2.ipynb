{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [75.06 / 95.58] Organización de Datos <br> Trabajo Práctico 2: Machine Learning\n",
    "# Notebook Principal\n",
    "\n",
    "**Grupo 30: Datatouille**\n",
    "\n",
    "- 101055 - Bojman, Camila\n",
    "- 100029 - del Mazo, Federico\n",
    "- 100687 - Hortas, Cecilia\n",
    "- 97649 - Souto, Rodrigo\n",
    "\n",
    "**http://fdelmazo.github.io/7506-Datos/**\n",
    "\n",
    "**https://www.kaggle.com/datatouille2018/competitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando la investigación sobre la empresa Trocafone realizada en el [TP1](https://fdelmazo.github.io/7506-Datos/TP1/TP1.html), se busca determinar la probabilidad de que un usuario del sitio realice una conversión en el período determinado.\n",
    "\n",
    "Notebooks en orden de corrida y lectura:\n",
    "\n",
    "0. [TP1](https://fdelmazo.github.io/7506-Datos/TP1/TP1.html) --> Familiarización con el set de datos y exploración de estos.\n",
    "\n",
    "1. [Investigación Previa](https://fdelmazo.github.io/7506-Datos/TP2/investigacion.html) --> Con ayuda de lo trabajado en el TP1, se averiguan más cosas de las datos, en busqueda de que poder reutilizar.\n",
    "\n",
    "2. [Creación de Dataframes](https://fdelmazo.github.io/7506-Datos/TP2/new_dataframes.html) --> Como parte del feature engineering, se crean dataframes nuevos con información de los productos del sitio y de como se accede a este (marcas, sistemas operativos, etc).\n",
    "\n",
    "3. [Feature Engineering](https://fdelmazo.github.io/7506-Datos/TP2/feature_engineering.html) --> Busqueda de atributos de los usuarios de los cuales se busca predecir la conversión.\n",
    "\n",
    "4. [Submission Framework](https://fdelmazo.github.io/7506-Datos/TP2/submission_framework.html) --> Pequeño framework para construir las postulaciones de labels. \n",
    "\n",
    "5. [Parameter Tuning](https://fdelmazo.github.io/7506-Datos/TP2/parameter_tuning.html) --> Busqueda de los mejores hiper-parametros para cada algoritmo de ML.\n",
    "\n",
    "6. [Feature Selection](https://fdelmazo.github.io/7506-Datos/TP2/feature_selection.html) --> Busqueda de la combinación de features más favorable.\n",
    "\n",
    "7. TP2 (este notebook)--> Teniendo todo en cuenta, usando los dataframes con todos los atributos buscados y encontrados, se definen y aplican los algoritmos de clasificación, se realizan los entrenamientos y posteriores predicciones de conversiones y finalmente se arman las postulaciones de labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Antes de comenzar, setear las credenciales (usuario y token)**\n",
    "1. Visitar: https://www.kaggle.com/datatouille2018/account (con la cuenta que sea)\n",
    "2. Tocar en Create New API Token\n",
    "3. Guardar el archivo descargado en ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -q data/events_up_to_01062018.zip -d data\n",
    "\n",
    "# !pip install kaggle\n",
    "# !pip install nbimporter\n",
    "# !conda install -y -c conda-forge xgboost \n",
    "# !conda install -y -c conda-forge lightgbm \n",
    "# !conda install -y -c conda-forge catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter # pip install nbimporter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from parameter_tuning import get_hiper_params\n",
    "from feature_selection import get_feature_selection\n",
    "import submission_framework as SF\n",
    "\n",
    "seed = 42\n",
    "hiper_params = get_hiper_params()\n",
    "feature_selection = get_feature_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('data/user-features.csv',low_memory=False).set_index('person')\n",
    "df_y = pd.read_csv('data/labels_training_set.csv').groupby('person').sum()\n",
    "\n",
    "display(df_users.head(), df_y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posibilidades_algoritmos = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "model_name = 'decision_tree'\n",
    "params = hiper_params[model_name]\n",
    "model = DecisionTreeClassifier(**params,random_state=seed)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_name = 'random_forest'\n",
    "params = hiper_params[model_name]\n",
    "model = RandomForestClassifier(**params,random_state=seed)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb #conda install -c conda-forge xgboost \n",
    "\n",
    "model_name = 'xgboost'\n",
    "params = hiper_params[model_name]\n",
    "model = xgb.XGBClassifier(**params,random_state=seed)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_name = 'knn'\n",
    "params = hiper_params[model_name]\n",
    "K = params['n_neighbors']\n",
    "model_name = f'KNN{K}'\n",
    "\n",
    "model = KNeighborsClassifier(**params)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model_name = 'naive_bayes'\n",
    "params = hiper_params[model_name]\n",
    "model = GaussianNB(**params)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb  #conda install -c conda-forge lightgbm \n",
    "\n",
    "model_name = 'lightgbm'\n",
    "params = hiper_params[model_name]\n",
    "model = lgb.LGBMClassifier(**params)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_name = 'neuralnetwork'\n",
    "params = hiper_params[model_name]\n",
    "model = MLPClassifier(**params)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb #conda install -c conda-forge catboost\n",
    "\n",
    "model_name = 'catboost'\n",
    "params = hiper_params[model_name]\n",
    "\n",
    "model = cb.CatBoostClassifier(**params,verbose=False)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC  \n",
    "\n",
    "model_name = 'gradient_boosting'\n",
    "params = hiper_params[model_name]\n",
    "\n",
    "model = GBC(**params)\n",
    "model_with_name = (model_name,model)\n",
    "\n",
    "SF.full_framework_wrapper(df_users,df_y,model_with_name)\n",
    "posibilidades_algoritmos.append(model_with_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Encontrando el mejor submit\n",
    "\n",
    "Corremos todos los algoritmos definidos sobre esas combinaciones, incluso ensamblados, en busqueda de su mejor combinación de hiper-parametros.\n",
    "\n",
    "Finalmente, se corren todos los algoritmos en su mejor combinación contra todos los set de features definidos, en busqueda de la mejor fusión universal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_mano = ['total_checkouts_month_5',\n",
    "                    'timestamp_last_checkout',\n",
    "                    'timestamp_last_event',\n",
    "                    'has_checkout_month_5',\n",
    "                    'total_checkouts',\n",
    "                    'days_to_last_event',\n",
    "                    'total_checkouts_last_week',\n",
    "                    'total_checkouts_months_1_to_4',\n",
    "                    'total_conversions',\n",
    "                    'total_session_conversion',\n",
    "                    'total_events',\n",
    "                    'total_sessions',\n",
    "                    'avg_events_per_session',\n",
    "                    'total_session_checkout',\n",
    "                    'has_checkout'\n",
    "                    ]\n",
    "\n",
    "columnas_a_mano_2 = ['dow_last_conversion', \n",
    "                     'has_conversion_last_week', 'total_conversions_month_4', \n",
    "                     'total_session_checkout', 'doy_last_conversion', 'timestamp_last_event', \n",
    "                     'dow_last_checkout', 'total_checkouts', 'has_checkout', 'doy_last_checkout', \n",
    "                     'has_checkout_month_1', 'timestamp_last_checkout', 'total_sessions', \n",
    "                     'woy_last_event', 'has_checkout_month_5', 'avg_events_per_session']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posibilidades_features = {\n",
    "    'Full Dataframe':[],\n",
    "    'Cumulative Importance':feature_selection['best_features_progresivo'],\n",
    "    'Forward Selection':feature_selection['best_features_forward'],\n",
    "    'Backward Elimination':feature_selection['best_features_backward'],\n",
    "    'Stepwise Regression ':feature_selection['best_features_stepwise'],\n",
    "    'Selección a Mano': columnas_a_mano,\n",
    "    'Selección a Mano 2': columnas_a_mano_2\n",
    "}\n",
    "\n",
    "todo_junto = [x for f in posibilidades_features.values() for x in f]\n",
    "intersec = list(set([x for x in todo_junto if todo_junto.count(x)>=2]))\n",
    "\n",
    "posibilidades_features['Feature Intersection'] = intersec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "                             \n",
    "def ensamblar_algoritmos(n):\n",
    "    result = list(combinations(posibilidades_algoritmos, n))\n",
    "    result_names = [f'{x[0][0]}+{x[1][0]}' for x in result]\n",
    "    return list(zip(result_names,result))\n",
    "\n",
    "def ensamble_tres_a_mano(nombre1,nombre2,nombre3):\n",
    "    result = list(combinations(posibilidades_algoritmos, 3))\n",
    "    for r in result:\n",
    "        names = [x[0] for x in r]\n",
    "        if nombre1 in names and nombre2 in names and nombre3 in names:\n",
    "            result_names = '+'.join(names)\n",
    "            return (result_names,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posibilidades_algoritmos_y_ensambles = posibilidades_algoritmos + ensamblar_algoritmos(2)\n",
    "posibilidades_algoritmos_y_ensambles += [ensamble_tres_a_mano('lightgbm','neuralnetwork','gradient_boosting')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forma, features in posibilidades_features.items():\n",
    "    print(f'{forma}:')\n",
    "    for nombre,algoritmo in posibilidades_algoritmos_y_ensambles`:\n",
    "        print('\\t * ',end='')\n",
    "        model_with_name = (f'{nombre}',algoritmo)\n",
    "        model, auc = SF.full_framework_wrapper(df_users, df_y, model_with_name, columns=features)\n",
    "        resultados.append((auc, forma, (nombre, algoritmo), features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.sort(reverse=True)\n",
    "display([(x[0],x[1],x[2][0]) for x in resultados])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_auc, campeon_forma, (campeon_nombre, campeon_algoritmo), campeon_features = resultados[0]\n",
    "display(f\"Mejor Apuesta: {campeon_nombre} ({max_auc:.4f} AUC) - Features: {campeon_forma}\")\n",
    "display(f\"Features: {campeon_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrida Final\n",
    "\n",
    "Se corre entrenando con X (y no X_train) el submit final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ensamble = 300\n",
    "\n",
    "campeon_model, campeon_auc, csv_name, campeon_message = SF.full_framework_wrapper(df_users, \n",
    "                                                                                    df_y, \n",
    "                                                                                    (campeon_nombre,campeon_algoritmo),\n",
    "                                                                                    columns=campeon_features,\n",
    "                                                                                    n_ensamble=n_ensamble,\n",
    "                                                                                    submit=True,\n",
    "                                                                                    all_in=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Descomentar y submitear!\n",
    "## Ojo, solo correr una vez!!!\n",
    "\n",
    "#!kaggle competitions submit -f {csv_name} -m \"{campeon_message}\" trocafone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quemar 9 submits de punta a punta \n",
    "\n",
    "# n_ensamble = 5\n",
    "\n",
    "# for resultado in resultados[1:10]:\n",
    "#     max_auc, campeon_forma, (campeon_nombre, campeon_algoritmo), campeon_features = resultado\n",
    "#     campeon_model, campeon_auc, csv_name, campeon_message = SF.full_framework_wrapper(df_users, \n",
    "#                                                                                     df_y, \n",
    "#                                                                                     (campeon_nombre,campeon_algoritmo),\n",
    "#                                                                                     columns=campeon_features,\n",
    "#                                                                                     n_ensamble=n_ensamble,\n",
    "#                                                                                     submit=True,\n",
    "#                                                                                     all_in=True)   \n",
    "#     !kaggle competitions submit -f {csv_name} -m \"{campeon_message}\" trocafone\n",
    "#     sleep(10)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions leaderboard -d trocafone\n",
    "#!unzip -o trocafone.zip\n",
    "print('Last Best Score')\n",
    "!cat trocafone-publicleaderboard.csv | grep Datatouille | tail -n 1 | awk '{split($0,a,\",\"); print \"\\t Fecha: \" a[3] ; print \"\\t Porcentaje: \" a[4]}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/trocafone/submissions?sortBy=date\n",
    "\n",
    "https://www.kaggle.com/c/trocafone/leaderboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Contenido",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.867px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
